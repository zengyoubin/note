# MySQL基本架构

### MySQL可以分为两层Server层和存储引擎层。

![MySQL逻辑架构图](image/0d2070e8f84c4801adbfa03bda1f98d9.png)

#### Server层

#### 连接器

​	连接器负责跟客户端建立连接、获取权限、维持和管理连接。

​	客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 `wait_timeout` 控制的，默认值是 **8** 小时

#### 查询缓存

​	MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。

​	如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。

​	查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。

​	**对于更新操作频繁的表查询缓存往往弊大于利**

​	MySQL 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。

#### 分析器

​	分析器先会做“词法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。

#### 优化器

​	优化器是在表里面有多个索引的时候，决定使用哪个索引。

#### 执行器

​	开始执行的时候，要先判断用户对该表有查询权限，没有则返回没有权限错误。（在命中缓存时，会再查询缓存返回寄过的时候做权限验证，查询也会在优化器之前调用precheck验证权限）。

​	接下来执行器会根据标的引擎定义，去使用这个引擎提供的接口。

# MySQL查询

### 边读边发

1. 获取一行，写到 `net_buffer` 中。这块内存的大小是由参数 `net_buffer_length` 定义的，默认是 16k。
2. 重复获取行，直到 net_buffer 写满，调用网络接口发出去。
3. 如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。
4. 如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。

### count(*)

​	InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。

​	**count(字段)<count(主键 id)<count(1)≈count(*)**

### order by

#### 全字段排序

![](image/826579b63225def812330ef6c344a303.png)

​	Extra 这个字段中的`Using filesort`表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为` sort_buffer`。可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 `sort_buffer_size`。

#### rowid 排序

​	`max_length_for_sort_data`，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。

### JOIN 查询

#### Index Nested-Loop Join（NLJ）

​	类似于嵌套查询，并且可以可以用上被驱动表的索引。

	1. 使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好；
 	2. 如果使用 join 语句的话，需要让小表做驱动表。

#### Simple Nested-Loop Join（）



# MySQL更新

## 两阶段提交

​	update语句更新流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。

![mysql update 更新流程如](image/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png)

#### redo log 和 binlog 是怎么关联起来的?

​	它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：

- 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
- 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。

## change buffer

​	当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

​	需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。

​	将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。

​	显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。

#### 唯一索引的更新操作不能使用change buffer

​	对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。

​	change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 `innodb_change_buffer_max_size` 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

​	数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

# InnoDB 存储

​	**当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。**

### 缓冲池（buffer pool）

​	InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：

- 第一种是，还没有使用的；
- 第二种是，使用了并且是干净页；
- 第三种是，使用了并且是脏页。

### 刷脏页（flush）

- redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。
- 系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。
- MySQL 认为系统“空闲”的时候。
- 对应的就是 MySQL 正常关闭

#### InnoDB 刷脏页的控制策略

- `innodb_io_capacity` 这个参数会告诉InnoDB磁盘能力，建议设置成磁盘的IOPS
- `innodb_max_dirty_pages_pct`脏页比例上限，默认值是 75%。

​	InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字，计算这个数字的伪代码类似这样：

```c
F1(M)
{
  if M >= innodb_max_dirty_pages_pct then
      return 100;
  return 100 * M / innodb_max_dirty_pages_pct;
}
```

​	InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。F2(N) 算法比较复杂，你只要知道 N 越大，算出来的值越大就好了。

​	根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。

​	脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的。

```sql
select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';
select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';
select @a/@b;
```

- `innodb_flush_neighbors`值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。

### 数据删除

- `innodb_file_per_table`控制表数据是放在系统表空间还是存储在以`.ibd`为后缀的文件中。建议ON
- delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的,造成数据“空洞”（插入数据也会造成空洞）。

#### 重建表

​	使用`alter table XXX engine=InnoDB`命令来重建表,**MySQL5.6版本后是Online DDL**

![Online DDL](image/2d1cfbbeb013b851a56390d38b5321f0.png)





# 事务

​	**ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）**

​	当数据库上有多个事务同时执行的时候，就可能出现**脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）**的问题，为了解决这些问题，就有了“**隔离级别**”的概念。

​	SQL 标准的事务隔离级别包括：**读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）**

- 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
- 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
- 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
- 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

### 事务隔离的实现

​	在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值（即是undo log）。

![undo log示意图](image/d9c313809e5ac148fc39feff532f0fee.png)

​	如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的**多版本并发控制（MVCC）**。undo log在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些undo log时，回滚日志会被删除。

### “快照”在MVCC的工作原理

​	在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。

​	InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。

​	而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。

​	也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。

​	![行状态变更图](image/68d08d277a6f7926a41cc5541d3dfced.png)

​	在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。

​	数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。

​	这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。

![数据版本可见性规则](image/882114aaf55861832b4270d44507695e.png)

对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能：

1. 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；
2. 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；
3. 如果落在黄色部分，那就包括两种情况
   1.  若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；
   2.  若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。

针对以上进行具体示例分析：

```sql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `k` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
insert into t(id, k) values(1,1),(2,2);
```

![事务A、B、C的执行流程](image/823acf76e53c0bdba7beab45e72e90d6.png)

根据上面三个事务情况，分析下事务 A 的语句返回的结果，为什么是 k=1。

这里，我们不妨做如下假设：

1. 事务 A 开始前，系统里面只有一个活跃事务 ID 是 99；
2. 事务 A、B、C 的版本号分别是 100、101、102，且当前系统里只有这四个事务；
3. 三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。

这样，事务 A 的视图数组就是`[99,100]`, 事务 B 的视图数组是`[99,100,101]`, 事务 C 的视图数组是`[99,100,101,102]`。

![事务A查询](image/9416c310e406519b7460437cb0c5c149.png)

​	从图中可以看到，第一个有效更新是事务 C，把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的最新版本的 row trx_id 是 102，而 90 这个版本已经成为了历史版本。

​	第二个有效更新是事务 B，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 row trx_id）是 101，而 102 又成为了历史版本。你可能注意到了，在事务 A 查询的时候，其实事务 B 还没有提交，但是它生成的 (1,3) 这个版本已经变成当前版本了。但这个版本对事务 A 必须是不可见的，否则就变成脏读了。

​	现在事务 A 要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前版本读起的。所以，事务 A 查询语句的读数据流程是这样的：

1. 找到 (1,3) 的时候，判断出 row trx_id=101，比高水位大，处于红色区域，不可见；
2. 接着，找到上一个历史版本，一看 row trx_id=102，比高水位大，处于红色区域，不可见；
3. 再往前找，终于找到了（1,1)，它的 row trx_id=90，比低水位小，处于绿色区域，可见。



总结：一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：

1. **版本未提交，不可见；**
2. **版本已提交，但是是在视图创建后提交的，不可见；**
3. **版本已提交，而且是在视图创建前提交的，可见。**

##### 更新规则

​	**更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。**

​	除了 update 语句外，select 语句如果加锁，也是当前读。

​	如果把事务 A 的查询语句 select * from t where id=1 修改一下，加上 lock in share mode 或 for update，也都可以读到版本号是 101 的数据，返回的 k 的值是 3。下面这两个 select 语句，就是分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。

```sql
mysql> select k from t where id=1 lock in share mode;
mysql> select k from t where id=1 for update;
```













































### 查看长事务

​	可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。

```sql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```



# 索引

​	索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。

### 索引的常见模型

三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。

- 哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。
- 有序数组索引只适用于静态存储引擎
- N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。

### InnoDB 的索引

​	在 InnoDB 中，表都是根据**主键顺序以索引的形式存放**的，这种存储方式的表称为**索引组织表**。InnoDB 使用了 **B+ 树索引模型**，所以数据都是存储在 B+ 树中的。

###### 示例

​	假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。

​	这个表的建表语句是：

```sql

create table T(
  id int primary key, 
  k int not null, 
  name varchar(16),
  index (k)
)engine=InnoDB;
```

​	表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下。

![inno db 索引组织结构图](image/dcda101051f28502bd5c4402b292e38d.png)

根据叶子节点的内容，索引类型分为主键索引和非主键索引。

- 主键索引的叶子节点存的是**整行数据**。在 InnoDB 里，主键索引也被称为**聚簇索引（clustered index）**。

- 非主键索引的叶子节点内容是**主键的值**。在 InnoDB 里，非主键索引也被称为**二级索引（secondary index）**。

**基于主键索引和普通索引的查询的区别**

- 如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；
- 如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为**回表**。

#### 索引维护

​	B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。

​	而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。

​	当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。

​	**主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小**

#### 覆盖索引

​	**覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**

#### 最左前缀原则

​	**B+树的索引结构，可以利用索引的“最左前缀”，来定位记录。**

​	字符串可指定所有前缀长度，使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。

​	如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。

#### 索引下推

​	MySQL5.6引入索引下推优化（index condition pushdown），可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

### 优化器的逻辑

​	选择索引是优化器的工作，而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。

​	**扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。**

#### 扫描行数是怎么判断的？

​	MySQL根据统计信息来估算记录数。这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。可以使用 `show index` 方法，看到一个索引的基数。

##### MySQL 是怎样得到索引的基数的呢？

​	MySQL 采样统计的方法。采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。

​	而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。

​	在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 `innodb_stats_persistent` 的值来选择：

- 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。
- 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。

索引统计信息不准确的问题，可以使用`analyze table`解决

# MySQL锁

​	**根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类。**

## 全局锁

​	**全局锁是对整个数据库实例加锁，典型使用场景是，做全库逻辑备份**。语法是`Flush tables with read lock (FTWRL)`，使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作都会被阻塞。

​	官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数`–single-transaction` 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。

​	**一致性读是好，但前提是引擎要支持这个隔离级别。**比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。所以，**single-transaction 方法只适用于所有的表使用事务引擎的库。**如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。

## 表级锁

### 表锁

​	表锁的语法是`lock tables xxx read/write `，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

### 元数据锁（meta data lock，MDL)

​	MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。

​	当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。

- 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
- 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

## 行锁

### 两阶段锁

​	**InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。**

### 死锁和死锁检测

​	出现死锁后有两种策略：

- 直接进入等待，直到超时。这个超时时间可以通过参数 `innodb_lock_wait_timeout` 来设置。

- 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 on，表示开启这个逻辑。

正常情况下采用第二种策略，但是有额外的负担，每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。

## 间隙锁

​	锁的是两个值之间的空隙。跟间隙锁存在冲突的关系的，是“往这个间隙中插入一个记录”这个操作，间隙锁之间不存在冲突关系。

## Next-key lock

​	Next-key lock = gap lock （间隙锁） + record lock （行锁）

#### 加锁规则

​	包含了两个“原则”、两个“优化”和一个“bug”

1. 原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。
2. 原则 2：查找过程中访问到的对象才会加锁。
3. 优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
4. 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。
5. 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

# 日志模块

主要是Server层的`binlog`和Inno DB存储引擎层的`redo log 、undo log`

## `binlog`

​	binlog属于Server层，不具备`crash-safe`能力，只能用于归档。

​	事务执行过程中，先把日志写到`binlog cache`,事务提交的时候，再把`binlog cache`写到binlog中

![binlog 写盘](image/9ed86644d5f39efb0efec595abb92e3e.png)

#### 参数

- `sync_binlog`	为0时，每次提交事务只write，不fsync; 为1时，表示每次提交事务都会执行fsync;为N(N>1)时，每次提交事务都会write,但累计积累N个事务后才fsync。
- `binlog_cache_size` 控制单个线程内 `binlog cache` 所占的内存大小，如果超过了这个参数规定的大小，就要暂存到磁盘。

## `redo log`

##### WAL（Wirte-Ahead Logging）

​	先写日志，再写磁盘。具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。

##### `redo log`

​	InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写。

![redo log](image/16a7950217b3f0f4ed02db5db59562a7.png)

- `write pos` 是当前记录的位置，一边写一遍后移
- `check point` 是当前要擦除的位置，往后推移并且循环，擦除记录前要把记录更新到数据文件。
- `write pos` 和`check point`之间空着的部分，可以用来记录新的操作。如果`write pos`追上`check point`，表示redo log满了，这时候不能再执行新的更新，得停下里先擦掉一些记录，把`check point`往前推进。

  有了` redo log`，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 `crash-safe`。

​	事务执行过程中，先把日志写到`redo log buffer`,事务提交的时候，再把`redo log buffer`写到对应的`ib_logfile+数字`的文件中

![redo log 写盘](image/9d057f61d3962407f413deebc80526d4.png)

InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 `page cache`，然后调用 fsync 持久化到磁盘。

除了后台线程每秒的轮询操作外，还有两种场景会让一个没有提价ode事务的`redo log`写入磁盘中：

1. 一种是，`redo log buffer` 占用的空间即将达到 `innodb_log_buffer_size` 一半的时候，后台线程会主动写盘。（注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 `page cache`。）
2. 另一种是，并行的事务提交的时候，顺带将这个事务的 `redo log buffer` 持久化到磁盘。（假设一个事务 A 执行到一半，已经写了一些 `redo log` 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 `innodb_flush_log_at_trx_commit` 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 `redo log buffer` 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 `redo log buffer` 里的日志一起持久化到磁盘。）

#### 参数

- `innodb_flush_log_at_trx_commit` 为0时每次事务提交都只是把`redo log`留在`redo log buffer` 中；为1时每次事务提交都将`redo log` 直接持久化到磁盘;为3时表示每次事务提交都只是把`redo log`写到`page cache`;

#### 组提交（`group commit`）

​	日志逻辑序列号（`log sequence number`，LSN）。LSN 是单调递增的，用来对应 `redo log` 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。

​	LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。关于 LSN 和 redo log、checkpoint 的关系，我会在后面的文章中详细展开。

​	如图所示，是三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 `redo log buffer`，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。

![redo log 组提交](image/933fdc052c6339de2aa3bf3f65b188cc.png)

1. trx1 是第一个到达的，会被选为这组的 leader；
2. 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；
3. trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；
4. 这时候 trx2 和 trx3 就可以直接返回了。

##### binlog 和 redo log 组提交

![两阶段提交细化](image/5ae7d074c34bc5bd55c82781de670c28.png)

##### 参数

- `binlog_group_commit_sync_delay` 参数，表示延迟多少微秒后才调用 fsync;
- `binlog_group_commit_sync_no_delay_count` 参数，表示累积多少次以后才调用 fsync。

## binlog和redo log区别

1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志

